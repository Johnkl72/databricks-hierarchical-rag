# ğŸ§  Databricks Hierarchical RAG

Un sistema **End-to-End RAG (Retrieval-Augmented Generation)** de grado empresarial construido sobre la **Databricks Data Intelligence Platform**.

Este proyecto implementa una arquitectura **layout-aware** para procesar documentos tÃ©cnicos complejos (tablas, encabezados, normativas), orquestando la ingesta con **Delta Lake** y desplegando una interfaz segura aplicando principios **SOLID** y **Clean Code**.

---

## ğŸ“¸ Demo

- Arquitectura lÃ³gica  
- Interfaz de usuario  
- Estrategia de *Layout-aware Chunking*  
- Chatbot citando fuentes  

*(ver carpeta `/assets`)*

---

## ğŸš€ CaracterÃ­sticas Clave

### 1. Backend: Ingesta JerÃ¡rquica Inteligente

A diferencia de los RAGs tradicionales que fragmentan texto sin contexto, este sistema utiliza **Unstructured** y **Apache Spark** para:

- Detectar y respetar la estructura del documento (tÃ­tulos, secciones, tablas).
- Generar **resÃºmenes sintÃ©ticos por secciÃ³n** usando **Llama 3**, mejorando la recuperaciÃ³n semÃ¡ntica.
- Almacenar **metadatos enriquecidos** en **Delta Lake**.

---

### 2. Data Engineering: OrquestaciÃ³n Robusta

ImplementaciÃ³n de una **malla de trabajos** con **Databricks Workflows**, diseÃ±ada para producciÃ³n:

- âœ… **Carga Incremental**  
  Solo procesa archivos nuevos en el Data Lake.

- âœ… **Blocking Sync**  
  Garantiza consistencia esperando a que **Vector Search** finalice la indexaciÃ³n.

- âœ… **Auto-validaciÃ³n**  
  Ejecuta un *Golden Dataset* de preguntas para validar calidad antes de finalizar el job.

---

### 3. Frontend: IngenierÃ­a de Software

La interfaz no es un script aislado. Es una **Databricks App (Streamlit)** diseÃ±ada con arquitectura de software:

- **PatrÃ³n Factory**  
  Para la gestiÃ³n de clientes y conexiones.

- **DTOs (Data Transfer Objects)**  
  Tipado estricto para documentos recuperados.

- **Service Principals (OIDC)**  
  AutenticaciÃ³n segura sin credenciales hardcodeadas.

---

## ğŸ› ï¸ Tech Stack

- **Plataforma**: Databricks Data Intelligence Platform  
- **Compute**: Spark Serverless & Databricks Apps  
- **Storage**: Unity Catalog (Volumes & Delta Tables)  
- **Vector Database**: Databricks Vector Search (Hybrid Index)  
- **LLM Serving**: Meta Llama 3 (70B Instruct) vÃ­a Model Serving  
- **Frontend**: Streamlit  

---

## ğŸ“‚ Estructura del Proyecto

```bash
databricks-hierarchical-rag/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ app.py
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_ingest_table.py
â”‚   â”œâ”€â”€ 02_sync_index.py
â”‚   â””â”€â”€ 03_validate_rag.py
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ parsing_utils.py
â”œâ”€â”€ assets/
â””â”€â”€ README.md
```

---

## ğŸ”§ ConfiguraciÃ³n y Despliegue

### Prerrequisitos

- Workspace de Databricks con Unity Catalog habilitado.
- Endpoint de Model Serving activo.
- Endpoint de Databricks Vector Search.

---

### Paso 1: Configurar el Backend

```python
CATALOG = "workspace"
SCHEMA = "default"
VOLUME_PATH = "/Volumes/workspace/default/mydocuments/"
```

---

### Paso 2: Desplegar la App

1. Crear una nueva Databricks App.
2. Vincular la carpeta `app/`.
3. Configurar permisos del Service Principal en Unity Catalog.

---

## ğŸ§  Decisiones de Arquitectura

### Â¿Por quÃ© Layout-aware Chunking?

Preserva la jerarquÃ­a semÃ¡ntica y mejora la precisiÃ³n del RAG.

### Â¿Por quÃ© Blocking Sync?

Evita inconsistencias por indexaciÃ³n eventual.

### Principios SOLID en el Frontend

SRP aplicado separando conexiÃ³n, lÃ³gica RAG y UI.

---

## ğŸ¤ ContribuciÃ³n

Abre un issue antes de enviar un PR.

---

## ğŸ“ Licencia

Licencia myprojects.

---

## ğŸ‘¨â€ğŸ’» Autor

**Tu Nombre** Johnkl27
Data Engineer In Progress | Cloud Architecture Student  
